# React Handsfree Demo

ğŸš€ Prototype for GDG AI Hackathon 2025  
ğŸ Track: Humanâ€“Computer Interfaces  
ğŸ“œ License: MIT

## ğŸ§  About

A hands-free, gesture- and voice-controlled web UI built with React and Firebase. This project explores the future of touchless interaction by combining **hand gestures**, **voice commands**, and an **adaptive user interface** â€” all built using modern web technologies. It aims to provide accessible, private, and intuitive control for users in sterile, public, or accessibility-first contexts.

## âœ¨ Features

- ğŸ” **Gesture Recognition** (5+ gestures) â€” powered by TensorFlow.js or MediaPipe
- ğŸ™ï¸ **Voice Commands** (10+ intents) â€” via Web Speech API
- ğŸ§© **Context-Aware UI** â€” adapts layout based on user proximity and ambient light
- ğŸ§ª **Live Calibration Tool** â€” lets users teach new gestures and commands in-browser
- ğŸ“± PWA & mobile support

## ğŸ› ï¸ Tech Stack

- Next.js 14 with App Router
- TypeScript
- Tailwind CSS
- Firebase (Auth, Firestore, Cloud Functions)
- TensorFlow.js / MediaPipe (on-device)
- Web Speech API

## ğŸš§ Getting Started

```bash
# Clone the repository
git clone https://github.com/thomas0x2/react-handsfree-demo
cd react-handsfree-demo

# Install dependencies
pnpm install

# Start the development server
pnpm dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

## Project Goals

Create an accessible and intuitive hands-free web interface that can be controlled through:
- Gesture recognition
- Voice commands
- Camera-based interaction

## Development

This is a prototype for the GDG AI Hackathon 2025 focusing on human-computer interface innovations.
