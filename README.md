# React Handsfree Demo

🚀 Prototype for GDG AI Hackathon 2025  
🏁 Track: Human–Computer Interfaces  
📜 License: MIT

## 🧠 About

A hands-free, gesture- and voice-controlled web UI built with React and Firebase. This project explores the future of touchless interaction by combining **hand gestures**, **voice commands**, and an **adaptive user interface** — all built using modern web technologies. It aims to provide accessible, private, and intuitive control for users in sterile, public, or accessibility-first contexts.

## ✨ Features

- 🔍 **Gesture Recognition** (5+ gestures) — powered by TensorFlow.js or MediaPipe
- 🎙️ **Voice Commands** (10+ intents) — via Web Speech API
- 🧩 **Context-Aware UI** — adapts layout based on user proximity and ambient light
- 🧪 **Live Calibration Tool** — lets users teach new gestures and commands in-browser
- 📱 PWA & mobile support

## 🛠️ Tech Stack

- Next.js 14 with App Router
- TypeScript
- Tailwind CSS
- Firebase (Auth, Firestore, Cloud Functions)
- TensorFlow.js / MediaPipe (on-device)
- Web Speech API

## 🚧 Getting Started

```bash
# Clone the repository
git clone https://github.com/thomas0x2/react-handsfree-demo
cd react-handsfree-demo

# Install dependencies
pnpm install

# Start the development server
pnpm dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

## Project Goals

Create an accessible and intuitive hands-free web interface that can be controlled through:
- Gesture recognition
- Voice commands
- Camera-based interaction

## Development

This is a prototype for the GDG AI Hackathon 2025 focusing on human-computer interface innovations.
