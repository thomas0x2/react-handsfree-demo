# Hands-Free UI: Multimodal Web Interface for Touchless Interaction

ğŸš€ Prototype
ğŸ Track: Humanâ€“Computer Interfaces  
ğŸ“œ License: MIT

---

## ğŸ§  About

This project explores the future of touchless interaction by combining **hand gestures**, **voice commands**, and an **adaptive user interface** â€” all built using modern web technologies. It aims to provide accessible, private, and intuitive control for users in sterile, public, or accessibility-first contexts.

---

## âœ¨ Features

- ğŸ” **Gesture Recognition** (5+ gestures) â€” powered by TensorFlow.js or MediaPipe
- ğŸ™ï¸ **Voice Commands** (10+ intents) â€” via Web Speech API
- ğŸ§© **Context-Aware UI** â€” adapts layout based on user proximity and ambient light
- ğŸ§ª **Live Calibration Tool** â€” lets users teach new gestures and commands in-browser
- ğŸ“± PWA & mobile support

---

## ğŸ› ï¸ Stack

| Layer        | Technology                                    |
| ------------ | --------------------------------------------- |
| Frontend     | Next.js 14 (App Router) + React 18 + Tailwind |
| Backend      | Firebase (Auth, Firestore, Cloud Functions)   |
| AI / ML      | TensorFlow.js / MediaPipe (on-device)         |
| Voice Input  | Web Speech API                                |
| Deployment   | Vercel or Firebase Hosting                    |

---

## ğŸš§ Getting Started

```bash
git clone https://github.com/your-username/handsfree-ui
cd handsfree-ui
pnpm install
pnpm dev
